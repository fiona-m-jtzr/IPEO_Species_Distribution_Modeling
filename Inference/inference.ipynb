{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HfhkfWi122_"
      },
      "source": [
        "# Species distribution modeling with ensemble model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs3lVZ3txnD9"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm7WFC0kxnD9"
      },
      "source": [
        "### 1.1 Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9F6DIeninwdi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score, label_ranking_loss, roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyfKdc3M3T0N"
      },
      "source": [
        "## 2. Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GRM7y4Wnggx"
      },
      "source": [
        "### 2.1 Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/fionajetzer/Desktop/IPEO/Project/Project\n"
          ]
        }
      ],
      "source": [
        "os.getcwd()\n",
        "# If not set to Project, change current working directory to Project\n",
        "\n",
        "os.chdir(\"../\")  # move one level up\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"Test\")  # the folder containing geoplant_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from geoplant_dataset import GeoPlantDataset\n",
        "from multiprocessing import Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYZBZVEhUtzM",
        "outputId": "9ff1803e-0f52-47c0-8077-6c57423a72a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training shapes:\n",
            "Env: (5000, 22)\n",
            "Time-series: (5000, 161)\n",
            "Images: (5000, 3, 128, 128)\n",
            "Labels: (5000, 342)\n"
          ]
        }
      ],
      "source": [
        "env_train = pd.read_csv(\"data/env_variables_training.csv\")\n",
        "env_test  = pd.read_csv(\"data/env_variables_test.csv\")\n",
        "\n",
        "ts_train  = pd.read_csv(\"data/landsat_timeseries_training.csv\")\n",
        "ts_test   = pd.read_csv(\"data/landsat_timeseries_test.csv\")\n",
        "\n",
        "# ---- Numpy files ----\n",
        "img_train = np.load(\"data/satellite_patches_training.npy\")\n",
        "img_test  = np.load(\"data/satellite_patches_test.npy\")\n",
        "\n",
        "species_train = np.load(\"data/species_data_training.npy\")\n",
        "species_test  = np.load(\"data/species_data_test.npy\")\n",
        "\n",
        "print(\"Training shapes:\")\n",
        "print(\"Env:\", env_train.shape)\n",
        "print(\"Time-series:\", ts_train.shape)\n",
        "print(\"Images:\", img_train.shape)\n",
        "print(\"Labels:\", species_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUVsXn3xZbm3"
      },
      "source": [
        "### 2.2 Reshaping and removing columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SvwwWgNPZW0W"
      },
      "outputs": [],
      "source": [
        "# Extract coordinates\n",
        "train_lons = env_train.iloc[:, 1]\n",
        "train_lats = env_train.iloc[:, 2]\n",
        "test_lons = env_test.iloc[:, 1]\n",
        "test_lats = env_test.iloc[:, 2]\n",
        "\n",
        "env_train = env_train.values.astype(np.float32)\n",
        "env_test  = env_test.values.astype(np.float32)\n",
        "\n",
        "env_train = env_train[:, 3:]\n",
        "env_test  = env_test[:, 3:]\n",
        "\n",
        "mean_env = env_train.mean(axis=0)\n",
        "std_env = env_train.std(axis=0)\n",
        "env_train = (env_train - mean_env) / std_env\n",
        "env_test = (env_test - mean_env) / std_env\n",
        "\n",
        "\n",
        "ts_train = ts_train.values.astype(np.float32)\n",
        "ts_test  = ts_test.values.astype(np.float32)\n",
        "\n",
        "ts_train = ts_train[:, 1:161].reshape(-1, 40, 4)\n",
        "ts_test  = ts_test[:, 1:161].reshape(-1, 40, 4)\n",
        "\n",
        "mean_ts = ts_train.mean(axis=(0, 1))\n",
        "std_ts = ts_train.std(axis=(0, 1))\n",
        "ts_train = (ts_train - mean_ts) / std_ts\n",
        "ts_test = (ts_test - mean_ts) / std_ts\n",
        "\n",
        "\n",
        "img_train = img_train.astype(np.float32)/255.0\n",
        "img_test  = img_test.astype(np.float32)/255.0\n",
        "\n",
        "species_train = species_train.astype(np.float32)\n",
        "species_test  = species_test.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNpJytkCJjyS"
      },
      "source": [
        "### 2.3 Defining dataset class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2qBz2nuKFfl"
      },
      "source": [
        "### 2.4 Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz4660GqmMd_",
        "outputId": "3f172fd8-6479-4359-844e-aedb131f7199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 4000\n",
            "Val samples: 1000\n",
            "Test samples: 1\n"
          ]
        }
      ],
      "source": [
        "train_dataset = GeoPlantDataset(\n",
        "    images=img_train,\n",
        "    timeseries=ts_train,\n",
        "    tabular=env_train,\n",
        "    labels=species_train,\n",
        "    split='train',\n",
        "    val_split=0.2\n",
        ")\n",
        "\n",
        "val_dataset = GeoPlantDataset(\n",
        "    images=img_train,\n",
        "    timeseries=ts_train,\n",
        "    tabular=env_train,\n",
        "    labels=species_train,\n",
        "    split='val',\n",
        "    val_split=0.2\n",
        ")\n",
        "\n",
        "test_dataset = GeoPlantDataset(\n",
        "    images=np.expand_dims(img_test[100], axis=0),      # shape (1, C, H, W)\n",
        "    timeseries=np.expand_dims(ts_test[100], axis=0),   # shape (1, T)\n",
        "    tabular=np.expand_dims(env_test[100], axis=0),     # shape (1, F)\n",
        "    labels=np.expand_dims(species_test[100], axis=0),  # shape (1, num_species)\n",
        "    split='test'\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxzLNkv1LZ7L"
      },
      "source": [
        "## 3. Multimodal species distribution model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hkx4A2IJMSJ8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multimodal model created with parameters: 26884022\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# 3.1 TABULAR ENCODER (climate variables)\n",
        "# ------------------------------------------------------------\n",
        "class TabularEncoder(nn.Module):\n",
        "    def __init__(self, in_features=19, out_features=342):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "          nn.Linear(in_features, 64),\n",
        "          nn.BatchNorm1d(64),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.1),\n",
        "\n",
        "          nn.Linear(64, 128),\n",
        "          nn.BatchNorm1d(128),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.2),\n",
        "\n",
        "          nn.Linear(128, 256),\n",
        "          nn.BatchNorm1d(256),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.3),\n",
        "\n",
        "          nn.Linear(256, 512),\n",
        "          nn.BatchNorm1d(512),\n",
        "          nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.2 TEMPORAL ENCODER (Landsat quarterly 10-year series)\n",
        "#      Input shape: (batch, T=40, C=4)\n",
        "# ------------------------------------------------------------\n",
        "class TimeseriesEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=4, out_features=342):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional Backbone\n",
        "        self.features = nn.Sequential(\n",
        "            self._make_layer(in_channels, 32),\n",
        "            self._make_layer(32, 64),\n",
        "            self._make_layer(64, 128),\n",
        "            self._make_layer(128, 256),\n",
        "            self._make_layer(256, 512),\n",
        "        )\n",
        "\n",
        "        # Pooling\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "\n",
        "    def _make_layer(self, in_c, out_c):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv1d(in_c, out_c, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(out_c), # Added for stability\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, ts):\n",
        "        # ts shape: (B, T, C) -> (B, C, T)\n",
        "        ts = ts.permute(0, 2, 1)\n",
        "\n",
        "        x = self.features(ts)\n",
        "\n",
        "        # Global Average Pool: (B, 512, T) -> (B, 512)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.3 IMAGE ENCODER (Sentinel-2 RGB patches)\n",
        "#      Uses pretrained ResNet34 but outputs a 256-dim feature\n",
        "# ------------------------------------------------------------\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, num_species=342):\n",
        "        super().__init__()\n",
        "        # Load weights suited for natural images\n",
        "        base = resnet34(weights=\"DEFAULT\")\n",
        "\n",
        "        # Keep everything except final FC layer\n",
        "        self.backbone = nn.Sequential(*list(base.children())[:-1])\n",
        "\n",
        "        # Add FC\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        features = self.backbone(img)\n",
        "        x = self.head(features)\n",
        "        return x\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3.4 FUSION MODEL\n",
        "# ------------------------------------------------------------\n",
        "class MultimodalSpeciesModel(nn.Module):\n",
        "    def __init__(self, num_species=342):\n",
        "        super().__init__()\n",
        "        self.tabular = TabularEncoder()\n",
        "        self.temporal = TimeseriesEncoder()\n",
        "        self.image   = ImageEncoder()\n",
        "\n",
        "        fusion_dim = 3*512\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(fusion_dim,1536),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1536,1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_species)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, ts, tab):\n",
        "        f_img = self.image(img)\n",
        "        f_ts  = self.temporal(ts)\n",
        "        f_tab = self.tabular(tab)\n",
        "\n",
        "        fused = torch.cat([f_img, f_ts, f_tab], dim=1)\n",
        "        logits = self.fusion(fused)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "model = MultimodalSpeciesModel()\n",
        "print(\"Multimodal model created with parameters:\", sum(p.numel() for p in model.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Oyrtx79Q0mEY"
      },
      "outputs": [],
      "source": [
        "model_weights = \"Models/Multimodal/Multimodal_model.pth\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Instantiate encoders\n",
        "model = MultimodalSpeciesModel()\n",
        "\n",
        "# Load weights\n",
        "model.load_state_dict(torch.load(model_weights, map_location=device, weights_only=True))\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(loader, model, device):\n",
        "    model.eval()\n",
        "    \n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img, ts, env, y in loader:\n",
        "            img = img.to(device).float()\n",
        "            ts  = ts.to(device).float()\n",
        "            env = env.to(device).float()\n",
        "            y = y.to(device).float()\n",
        "\n",
        "            # Model outputs (probabilities)\n",
        "            batch_probs = torch.sigmoid(model(img, ts, env))\n",
        "            \n",
        "            # Store batch results\n",
        "            all_probs.append(batch_probs.cpu())   # move to CPU\n",
        "            all_labels.append(y.cpu())            # also store labels\n",
        "\n",
        "    # Concatenate all batches\n",
        "    all_probs = torch.cat(all_probs, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "    print(\"Probs shape:\", all_probs.shape)\n",
        "    print(\"Labels shape:\", all_labels.shape)\n",
        "\n",
        "    return all_probs, all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probs shape: torch.Size([1, 342])\n",
            "Labels shape: torch.Size([1, 342])\n"
          ]
        }
      ],
      "source": [
        "test_probs, test_labels = predict(model=model, loader=test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0kB-R_Dq6dP",
        "outputId": "bfd0a059-93d6-40b0-e2d5-cf7e5d00a6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probs shape: torch.Size([5000, 342])\n",
            "Labels shape: torch.Size([5000, 342])\n"
          ]
        }
      ],
      "source": [
        "full_train_data = GeoPlantDataset(tabular=env_train,images=img_train, timeseries=ts_train, labels=species_train, split=None)\n",
        "train_loader = DataLoader(full_train_data, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "train_pred, train_label = predict(train_loader,\n",
        "                     model,\n",
        "                     device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6b1qhnmErQac"
      },
      "outputs": [],
      "source": [
        "def find_optimal_thresholds(y_true, probs):\n",
        "    \"\"\"\n",
        "    Finds the best threshold for each of the 342 species.\n",
        "    \n",
        "    Args:\n",
        "        y_true: Ground truth labels (N, 342) -> torch.Tensor or np.ndarray\n",
        "        probs: Training predictions (N, 342) -> torch.Tensor or np.ndarray\n",
        "\n",
        "    Returns:\n",
        "        best_thresholds: np.ndarray of shape (342,) with optimized thresholds\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert tensors to NumPy if needed\n",
        "    if isinstance(y_true, torch.Tensor):\n",
        "        y_true = y_true.cpu().numpy()\n",
        "    if isinstance(probs, torch.Tensor):\n",
        "        probs = probs.cpu().numpy()\n",
        "\n",
        "    num_species = y_true.shape[1]\n",
        "    best_thresholds = np.zeros(num_species)\n",
        "    thresholds = np.linspace(0, 1, 100)\n",
        "\n",
        "    print(\"Optimizing thresholds for 342 species...\")\n",
        "\n",
        "    for i in range(num_species):\n",
        "        species_labels = y_true[:, i]\n",
        "        species_probs = probs[:, i]\n",
        "\n",
        "        # Default threshold if no positive samples\n",
        "        if species_labels.sum() == 0:\n",
        "            best_thresholds[i] = 0.5\n",
        "            continue\n",
        "\n",
        "        best_fbeta = -1\n",
        "        best_thresh = 0.5\n",
        "\n",
        "        for t in thresholds:\n",
        "            preds = (species_probs >= t).astype(int)\n",
        "            score = fbeta_score(species_labels, preds, beta=0.5, zero_division=0)\n",
        "\n",
        "            if score > best_fbeta:\n",
        "                best_fbeta = score\n",
        "                best_thresh = t\n",
        "\n",
        "        best_thresholds[i] = best_thresh\n",
        "\n",
        "    print(\"Optimization complete.\")\n",
        "    return best_thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PE9NJQprZjW",
        "outputId": "1a994226-f80d-4eb3-dd50-357a63348ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing thresholds for 342 species...\n",
            "Optimization complete.\n"
          ]
        }
      ],
      "source": [
        "opt_thresholds = find_optimal_thresholds(train_label, train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5HqYbPyGCk3",
        "outputId": "67cf2897-526e-41ff-85e9-0f4d37f57699"
      },
      "outputs": [],
      "source": [
        "binary_preds = (test_probs.cpu().numpy() >= opt_thresholds).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Species index predicted present: [ 15  30  56  81  94  96 113 128 135 143 187 212 252 263 268 272 282 304\n",
            " 315 338]\n",
            "Species index labeled present: [ 0 30]\n"
          ]
        }
      ],
      "source": [
        "idx_pred = np.nonzero(binary_preds)[1]\n",
        "idx_label = np.nonzero(test_labels)[1]\n",
        "print(\"Species index predicted present:\", idx_pred)\n",
        "print(\"Species index labeled present:\", idx_label.numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "IPEO_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
